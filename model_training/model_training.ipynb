{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:25.512240Z",
     "start_time": "2025-03-31T19:40:25.210583Z"
    }
   },
   "source": [
    "# Environment Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:26.238301Z",
     "start_time": "2025-03-31T19:40:26.235303Z"
    }
   },
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:27.229599Z",
     "start_time": "2025-03-31T19:40:26.977651Z"
    }
   },
   "source": [
    "# Define paths\n",
    "base_path = \"../dataset/data_exploration/\"\n",
    "metadata_path = \"../dataset/dataverse_files/\"\n",
    "\n",
    "# Load feature files\n",
    "color_var = pd.read_csv(os.path.join(base_path, \"color_variance_features.csv\"))\n",
    "color_hist = pd.read_csv(os.path.join(base_path, \"combined_color_histogram_features.csv\"))\n",
    "lbp = pd.read_csv(os.path.join(base_path, \"combined_lbp_features.csv\"))\n",
    "glcm = pd.read_csv(os.path.join(base_path, \"glcm_features.csv\"))\n",
    "metadata = pd.read_csv(os.path.join(metadata_path, \"HAM10000_metadata\"))\n",
    "\n",
    "# Function to extract image_id from file_name\n",
    "def extract_image_id(file_name):\n",
    "    # Extract the base name (e.g., 'ISIC_0024306.jpg')\n",
    "    base_name = file_name.split('\\\\')[-1]\n",
    "    # Remove the file extension (e.g., '.jpg')\n",
    "    image_id = os.path.splitext(base_name)[0]\n",
    "    return image_id\n",
    "\n",
    "# Apply the function to extract image_id\n",
    "color_var['image_id'] = color_var['file_name'].apply(extract_image_id)\n",
    "color_hist['image_id'] = color_hist['file_name'].apply(extract_image_id)\n",
    "lbp['image_id'] = lbp['file_name'].apply(extract_image_id)\n",
    "glcm['image_id'] = glcm['file_name'].apply(extract_image_id)\n",
    "\n",
    "# Sort feature DataFrames by image_id\n",
    "color_var_sorted = color_var.sort_values(by='image_id').reset_index(drop=True)\n",
    "color_hist_sorted = color_hist.sort_values(by='image_id').reset_index(drop=True)\n",
    "lbp_sorted = lbp.sort_values(by='image_id').reset_index(drop=True)\n",
    "glcm_sorted = glcm.sort_values(by='image_id').reset_index(drop=True)\n",
    "\n",
    "# Sort metadata by image_id\n",
    "metadata_sorted = metadata.sort_values(by='image_id').reset_index(drop=True)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:27.803898Z",
     "start_time": "2025-03-31T19:40:27.800147Z"
    }
   },
   "source": [
    "# Check for consistency\n",
    "print(\"Feature image_id after sorting:\", color_var_sorted['image_id'].head())\n",
    "print(\"Metadata image_id after sorting:\", metadata_sorted['image_id'].head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature image_id after sorting: 0    ISIC_0024306\n",
      "1    ISIC_0024307\n",
      "2    ISIC_0024308\n",
      "3    ISIC_0024309\n",
      "4    ISIC_0024310\n",
      "Name: image_id, dtype: object\n",
      "Metadata image_id after sorting: 0    ISIC_0024306\n",
      "1    ISIC_0024307\n",
      "2    ISIC_0024308\n",
      "3    ISIC_0024309\n",
      "4    ISIC_0024310\n",
      "Name: image_id, dtype: object\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:28.548279Z",
     "start_time": "2025-03-31T19:40:28.513095Z"
    }
   },
   "source": [
    "# Merge all features\n",
    "def merge_features(df_list):\n",
    "    # Start with the first DataFrame\n",
    "    merged = df_list[0]\n",
    "    # Merge the rest\n",
    "    for df in df_list[1:]:\n",
    "        merged = pd.merge(merged, df, on='image_id', how='inner', suffixes=('', '_dup'))\n",
    "        # Drop duplicate columns\n",
    "        merged = merged.loc[:, ~merged.columns.str.endswith('_dup')]\n",
    "    return merged\n",
    "\n",
    "# List of sorted feature DataFrames\n",
    "feature_dfs = [color_var_sorted, color_hist_sorted, lbp_sorted, glcm_sorted]\n",
    "merged_features = merge_features(feature_dfs)\n",
    "\n",
    "# Add metadata (dx column)\n",
    "full_data = merged_features.copy()\n",
    "full_data['dx'] = metadata_sorted['dx']"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:29.301207Z",
     "start_time": "2025-03-31T19:40:29.296321Z"
    }
   },
   "source": [
    "# Check the full data\n",
    "print(\"Full Data Shape:\", full_data.shape)\n",
    "print(\"Full Data Columns:\", full_data.columns)\n",
    "print(\"Class Distribution:\\n\", full_data['dx'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Shape: (10015, 122)\n",
      "Full Data Columns: Index(['file_name', 'folder', 'mean_r', 'mean_g', 'mean_b', 'var_r', 'var_g',\n",
      "       'var_b', 'overall_var', 'image_id',\n",
      "       ...\n",
      "       'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'contrast', 'dissimilarity',\n",
      "       'homogeneity', 'energy', 'correlation', 'dx'],\n",
      "      dtype='object', length=122)\n",
      "Class Distribution:\n",
      " dx\n",
      "nv       6705\n",
      "mel      1113\n",
      "bkl      1099\n",
      "bcc       514\n",
      "akiec     327\n",
      "vasc      142\n",
      "df        115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:30.039254Z",
     "start_time": "2025-03-31T19:40:30.020914Z"
    }
   },
   "source": [
    "# Data Preprocessing\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "full_data['label'] = le.fit_transform(full_data['dx'])\n",
    "\n",
    "# Define X and y (features and target)\n",
    "X = full_data.drop(columns=['label'])\n",
    "y = full_data['label']\n",
    "\n",
    "# Drop non-feature columns\n",
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Output removed columns\n",
    "removed_cols = list(set(X.columns) - set(X_numeric.columns))\n",
    "print(\"removed_cols:\", removed_cols)\n",
    "\n",
    "# Update X\n",
    "X = X_numeric\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"X Shape:\", X.shape)\n",
    "print(\"y Shape:\", y.shape)\n",
    "print(\"X Columns:\", X.columns)\n",
    "print(\"Class Distribution:\\n\", y.value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed_cols: ['dx', 'image_id', 'file_name', 'folder']\n",
      "X Shape: (10015, 118)\n",
      "y Shape: (10015,)\n",
      "X Columns: Index(['mean_r', 'mean_g', 'mean_b', 'var_r', 'var_g', 'var_b', 'overall_var',\n",
      "       'hist_r_0', 'hist_r_1', 'hist_r_2',\n",
      "       ...\n",
      "       'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'contrast',\n",
      "       'dissimilarity', 'homogeneity', 'energy', 'correlation'],\n",
      "      dtype='object', length=118)\n",
      "Class Distribution:\n",
      " label\n",
      "5    6705\n",
      "4    1113\n",
      "2    1099\n",
      "1     514\n",
      "0     327\n",
      "6     142\n",
      "3     115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:31.102675Z",
     "start_time": "2025-03-31T19:40:31.095748Z"
    }
   },
   "source": [
    "# Model Pipeline Setup\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# SVM Pipeline\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('svm', SVC(probability=True, random_state=SEED))\n",
    "])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('rf', RandomForestClassifier(random_state=SEED))\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:31.833026Z",
     "start_time": "2025-03-31T19:40:31.829338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "# # SVM Hyperparameters\n",
    "# svm_params = {\n",
    "#     'svm__C': [0.01],\n",
    "#     'svm__kernel': ['linear'],\n",
    "#     'svm__gamma': ['scale'],\n",
    "#     'svm__class_weight': [None, 'balanced']\n",
    "# }\n",
    "\n",
    "svm_params = {\n",
    "    'svm__C': [0.001, .001, .01, 0.1],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'svm__gamma': ['scale', 'auto'],\n",
    "    'svm__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# # Random Forest Hyperparameters\n",
    "# rf_params = {\n",
    "#     'rf__n_estimators': [100],\n",
    "#     'rf__max_depth': [None, 10],\n",
    "#     'rf__min_samples_split': [2],\n",
    "#     'rf__min_samples_leaf': [2],\n",
    "#     'rf__class_weight': [None, 'balanced']\n",
    "# }\n",
    "\n",
    "rf_params = {\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:40:32.931151Z",
     "start_time": "2025-03-31T19:40:32.928350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tuning Strategy\n",
    "def tune_model(pipe, params, X, y):\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        params,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    return search.best_estimator_, search.best_params_"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:30:35.658506Z",
     "start_time": "2025-03-31T19:40:33.954864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM Tuning\n",
    "print(\"Tuning SVM...\")\n",
    "best_svm, svm_best_params = tune_model(svm_pipe, svm_params, X_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sj/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:42:55.157216Z",
     "start_time": "2025-03-31T20:30:36.086482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random Forest Tuning\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "best_rf, rf_best_params = tune_model(rf_pipe, rf_params, X_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:42:56.291882Z",
     "start_time": "2025-03-31T20:42:55.342554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Performance:\")\n",
    "evaluate_model(best_svm, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "evaluate_model(best_rf, X_test, y_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Performance:\n",
      "Accuracy: 0.7209\n",
      "F1 Score: 0.6767\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.49      0.42      0.45        65\n",
      "         bcc       0.40      0.26      0.32       103\n",
      "         bkl       0.50      0.35      0.41       220\n",
      "          df       0.00      0.00      0.00        23\n",
      "         mel       0.46      0.13      0.21       223\n",
      "          nv       0.77      0.95      0.85      1341\n",
      "        vasc       0.71      0.36      0.48        28\n",
      "\n",
      "    accuracy                           0.72      2003\n",
      "   macro avg       0.48      0.35      0.39      2003\n",
      "weighted avg       0.67      0.72      0.68      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  27   10    2    0    2   24    0]\n",
      " [  10   27    5    0    1   60    0]\n",
      " [   3   13   78    0   13  112    1]\n",
      " [   4    2    3    0    0   14    0]\n",
      " [   2    1   39    0   30  151    0]\n",
      " [   9   12   26    0   19 1272    3]\n",
      " [   0    3    4    0    0   11   10]]\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.7404\n",
      "F1 Score: 0.7293\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.49      0.43      0.46        65\n",
      "         bcc       0.40      0.47      0.43       103\n",
      "         bkl       0.49      0.44      0.47       220\n",
      "          df       0.67      0.09      0.15        23\n",
      "         mel       0.47      0.38      0.42       223\n",
      "          nv       0.84      0.90      0.87      1341\n",
      "        vasc       1.00      0.43      0.60        28\n",
      "\n",
      "    accuracy                           0.74      2003\n",
      "   macro avg       0.62      0.45      0.49      2003\n",
      "weighted avg       0.73      0.74      0.73      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  28   19    5    1    2   10    0]\n",
      " [  12   48   10    0    5   28    0]\n",
      " [   2   22   97    0   33   66    0]\n",
      " [   4    2    4    2    1   10    0]\n",
      " [   2    1   33    0   85  102    0]\n",
      " [   9   23   46    0   52 1211    0]\n",
      " [   0    4    1    0    1   10   12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sj/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sj/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sj/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:42:56.319881Z",
     "start_time": "2025-03-31T20:42:56.305861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Importance Analysis (RF Specific)\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf.named_steps['rf'].feature_importances_\n",
    "feature_names = X.columns\n",
    "feat_imp = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feat_imp = feat_imp.sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(feat_imp.head(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Important Features:\n",
      "      feature  importance\n",
      "78   hist_b_7    0.021240\n",
      "45   hist_g_6    0.019861\n",
      "103     lbp_0    0.019531\n",
      "46   hist_g_7    0.018812\n",
      "44   hist_g_5    0.018754\n",
      "79   hist_b_8    0.018018\n",
      "77   hist_b_6    0.017859\n",
      "108     lbp_5    0.017817\n",
      "106     lbp_3    0.017438\n",
      "112     lbp_9    0.017391\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:52:05.323084Z",
     "start_time": "2025-03-31T20:52:05.126788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save models\n",
    "joblib.dump(best_svm, 'best_svm_model.pkl')\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "# Save feature names\n",
    "with open('feature_names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(feature_names))"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T16:40:14.331825Z",
     "start_time": "2025-03-29T16:40:14.328522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Key Parameter Adjustment Strategies\n",
    "# \"\"\"\n",
    "# For SVM:\n",
    "# 1. Regularization (C):\n",
    "#    - Start with log scale values (0.1, 1, 10, 100)\n",
    "#    - Higher C = less regularization, might overfit\n",
    "#\n",
    "# 2. Kernel Selection:\n",
    "#    - Try linear first for baseline\n",
    "#    - RBF for non-linear relationships\n",
    "#    - Poly for complex patterns (but needs more data)\n",
    "#\n",
    "# 3. Gamma:\n",
    "#    - Controls decision boundary curvature\n",
    "#    - Lower values = larger influence radius\n",
    "#    - Use 'scale' (1/(n_features * X.var())) as baseline\n",
    "#\n",
    "# For Random Forest:\n",
    "# 1. n_estimators:\n",
    "#    - Start with 100-500 trees\n",
    "#    - More trees = better performance but longer training\"\n",
    "#\n",
    "# 2. max_depth:\n",
    "#    - Control tree complexity\n",
    "#    - None for full expansion (watch for overfitting)\n",
    "#\n",
    "# 3. class_weight:\n",
    "#    - Crucial for imbalanced datasets\n",
    "#    - 'balanced' adjusts weights inversely proportional to class frequencies\n",
    "#\n",
    "# 4. min_samples_split:\n",
    "#    - Higher values prevent overfitting\n",
    "#    - Start with 2 (default), try 5-10 for regularization\n",
    "# \"\"\"\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:07:41.389033Z",
     "start_time": "2025-03-30T16:07:41.337501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See how the svm model and rf models can potentially be improved with data augmentation\n",
    "\n",
    "# Data Augmentation\n",
    "def augment_data(data, num_augmentations=1, noise_level=0.01):\n",
    "    augmented_data = data.copy()\n",
    "    for _ in range(num_augmentations):\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "        augmented_sample = data + noise\n",
    "        augmented_data = pd.concat([augmented_data, augmented_sample], ignore_index=True)\n",
    "    return augmented_data\n",
    "\n",
    "# Augment the training data\n",
    "X_train_augmented = augment_data(X_train, num_augmentations=2, noise_level=0.01)\n",
    "\n",
    "# Repeat the target labels to match the augmented data\n",
    "y_train_augmented = pd.concat([y_train] * (2 + 1), ignore_index=True)  # Original + 2 augmentations\n",
    "\n",
    "print(\"Augmented X_train shape:\", X_train_augmented.shape)\n",
    "print(\"Augmented y_train shape:\", y_train_augmented.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented X_train shape: (24036, 119)\n",
      "Augmented y_train shape: (24036,)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:07:42.356878Z",
     "start_time": "2025-03-30T16:07:42.318008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to numpy arrays\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "\n",
    "# Standardize the data\n",
    "X_train_augmented = scaler.fit_transform(X_train_augmented)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sj/miniconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:10:13.067219Z",
     "start_time": "2025-03-30T16:07:50.874564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM Model\n",
    "svm_model_augmented = SVC(probability=True, random_state=SEED)\n",
    "svm_model_augmented.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model_augmented = RandomForestClassifier(random_state=SEED)\n",
    "rf_model_augmented.fit(X_train_augmented, y_train_augmented)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T17:43:23.712819Z",
     "start_time": "2025-03-30T16:12:49.677193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tune SVM\n",
    "print(\"Tuning SVM...\")\n",
    "best_svm_aug, svm_best_params_aug = tune_model(svm_pipe, svm_params, X_train_augmented, y_train_augmented)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sj/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 24 is smaller than n_iter=50. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tune Random Forest\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "best_rf_aug, rf_best_params_aug = tune_model(rf_pipe, rf_params, X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate models\n",
    "print(\"SVM with Augmented Data Performance:\")\n",
    "evaluate_model(best_svm_aug, X_test, y_test)\n",
    "\n",
    "print(\"\\nRandom Forest with Augmented Data Performance:\")\n",
    "evaluate_model(best_rf_aug, X_test, y_test)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save models\n",
    "joblib.dump(svm_model_augmented, 'svm_model_augmented.pkl')\n",
    "joblib.dump(rf_model_augmented, 'rf_model_augmented.pkl')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will try to use a CNN model to classify the skin cancer images. We will use the VGG16 architecture with transfer learning."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T16:40:17.695082Z",
     "start_time": "2025-03-29T16:40:15.311172Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 36,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset from huggingface\n",
    "train_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"validation\")\n",
    "test_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"test\")"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T16:40:18.706816Z",
     "start_time": "2025-03-29T16:40:18.703222Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9577, 8)\n",
      "{'image': Image(mode=None, decode=True, id=None), 'image_id': Value(dtype='string', id=None), 'lesion_id': Value(dtype='string', id=None), 'dx': Value(dtype='string', id=None), 'dx_type': Value(dtype='string', id=None), 'age': Value(dtype='float64', id=None), 'sex': Value(dtype='string', id=None), 'localization': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "execution_count": 37,
   "source": [
    "# save lengths of datasets for later use\n",
    "train_length = len(train_dataset) - 1 # Remove the first row\n",
    "valid_length = len(valid_dataset) - 1\n",
    "test_length = len(test_dataset) - 1\n",
    "\n",
    "# check the dataset\n",
    "print(train_dataset.shape)\n",
    "print(train_dataset.features)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:43:58.936710Z",
     "start_time": "2025-03-28T17:43:55.717306Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "# apply CNNs and transfer learning\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Retrieve number of classes\n",
    "num_classes = len(train_dataset.unique('dx'))\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return float(lr)\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "def build_model(hp):\n",
    "    base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(256, 128, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(hp.Int('units', min_value=128, max_value=512, step=64), activation='relu')(x)\n",
    "    x = keras.layers.Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    predictions = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:44:00.238106Z",
     "start_time": "2025-03-28T17:44:00.217390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to convert dataset to TensorFlow dataset\n",
    "def convert_to_tf_dataset(dataset):\n",
    "    def generator():\n",
    "        for data in dataset:\n",
    "            yield {'image': data['image'], 'dx': data['dx']}\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature={\n",
    "            'image': tf.TensorSpec(shape=(None, None, 3), dtype=tf.uint8),\n",
    "            'dx': tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Data Augmentation for Images\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "    keras.layers.RandomZoom(0.2),\n",
    "    keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Define normalization layer\n",
    "normalization_layer = keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Extract unique labels from the dataset\n",
    "unique_labels = train_dataset.unique('dx')\n",
    "\n",
    "# Create a lookup table mapping each label to a unique integer\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "\n",
    "# Function to preprocess and augment the dataset\n",
    "def preprocess_data(dataset, augment=False):\n",
    "    def preprocess_image(image, label):\n",
    "        image = tf.image.resize(image, (128, 128))\n",
    "        image = normalization_layer(image)\n",
    "        if augment:\n",
    "            image = data_augmentation(image)\n",
    "        label = label_to_index[label.numpy().decode('utf-8')]  # Convert string labels to integers\n",
    "        label = tf.one_hot(label, num_classes)  # One-hot encode the label\n",
    "        return image, label\n",
    "\n",
    "    def map_fn(data):\n",
    "        image = data['image']\n",
    "        label = data['dx']\n",
    "        image, label = tf.py_function(preprocess_image, [image, label], [tf.float32, tf.float32])\n",
    "        image.set_shape((128, 128, 3))\n",
    "        label.set_shape((num_classes,))\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(map_fn)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:44:01.271783Z",
     "start_time": "2025-03-28T17:44:01.241151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert datasets to TensorFlow datasets\n",
    "train_dataset = convert_to_tf_dataset(train_dataset)\n",
    "valid_dataset = convert_to_tf_dataset(valid_dataset)\n",
    "test_dataset = convert_to_tf_dataset(test_dataset)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:44:02.342989Z",
     "start_time": "2025-03-28T17:44:02.297331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "# Preprocess the datasets\n",
    "train_dataset = preprocess_data(train_dataset, augment=True) # Repeat the dataset 50 times to match epochs for training\n",
    "valid_dataset = preprocess_data(valid_dataset)\n",
    "test_dataset = preprocess_data(test_dataset)\n",
    "\n",
    "# Remove the first row from each dataset\n",
    "train_dataset = train_dataset.skip(1)\n",
    "valid_dataset = valid_dataset.skip(1)\n",
    "test_dataset = test_dataset.skip(1)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Cache and prefetch the datasets to improve performance\n",
    "train_dataset = train_dataset.take(train_length).cache().repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.cache().take(valid_length).repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().take(test_length).repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = math.ceil(train_length / 32)\n",
    "validation_steps = math.ceil(valid_length / 32)\n",
    "\n",
    "# Debugging Statement: Print dataset shapes and steps\n",
    "print(f\"Train dataset length: {train_length}, Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation dataset length: {valid_length}, Validation steps: {validation_steps}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 9576, Steps per epoch: 300\n",
      "Validation dataset length: 2491, Validation steps: 78\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T17:44:03.941696Z",
     "start_time": "2025-03-28T17:44:03.192401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the normalization\n",
    "normalized_ds = train_dataset.take(1).cache().map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in [0,1].\n",
    "print(np.min(first_image), np.max(first_image))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008656473 0.0033541827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:44:03.934699: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=4,\n",
    "    directory='my_dir',\n",
    "    project_name='cnn_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(train_dataset, validation_data=valid_dataset, epochs=50, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [01h 10m 28s]\n",
      "val_accuracy: 0.6685393452644348\n",
      "\n",
      "Best val_accuracy So Far: 0.6689406037330627\n",
      "Total elapsed time: 08h 03m 07s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T04:29:38.388869Z",
     "start_time": "2025-03-29T04:29:36.871306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameters.values)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'units': 192, 'dropout': 0.2, 'learning_rate': 0.0010158927858354443, 'tuner/epochs': 3, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T04:29:44.926450Z",
     "start_time": "2025-03-29T04:29:44.659475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save best model\n",
    "best_model.save('best_cnn_model.keras')"
   ],
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
