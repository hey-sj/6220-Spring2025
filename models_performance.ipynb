{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook is meant to serve as a summary notebook for the performance of the models trained in `model_training/model_training.ipynb` for ease of readability and comparison.\n",
    "\n",
    "Notes:\n",
    "We implemented data augmentation techniques like SMOTE, SVMSMOTE, and ADASYNC but performance was not improved. We also tried dimensionality reduction with PCA but performance worsened. We excluded these techniques from the final models. This indicates that the models may benefit from additional feature engineering, hyperparameter tuning, or use of other model architectures. However, due to computational and time constraints, we did not explore these options further but will provide detail in the final report."
   ],
   "id": "635997d561864d48"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:51.936533Z",
     "start_time": "2025-04-05T02:49:46.435661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Environment Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import itertools\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import itertools\n",
    "import math\n",
    "import gzip\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:51.944341Z",
     "start_time": "2025-04-05T02:49:51.941433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ],
   "id": "58f8d872d8df70eb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:52.362794Z",
     "start_time": "2025-04-05T02:49:52.107496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define paths\n",
    "base_path = \"dataset/data_exploration/\"\n",
    "metadata_path = \"dataset/dataverse_files/\"\n",
    "\n",
    "# Load feature files\n",
    "color_var = pd.read_csv(os.path.join(base_path, \"color_variance_features.csv\"))\n",
    "color_hist = pd.read_csv(os.path.join(base_path, \"combined_color_histogram_features.csv\"))\n",
    "lbp = pd.read_csv(os.path.join(base_path, \"combined_lbp_features.csv\"))\n",
    "glcm = pd.read_csv(os.path.join(base_path, \"glcm_features.csv\"))\n",
    "metadata = pd.read_csv(os.path.join(metadata_path, \"HAM10000_metadata\"))\n",
    "\n",
    "# Function to extract image_id from file_name\n",
    "def extract_image_id(file_name):\n",
    "    # Extract the base name (e.g., 'ISIC_0024306.jpg')\n",
    "    base_name = file_name.split('\\\\')[-1]\n",
    "    # Remove the file extension (e.g., '.jpg')\n",
    "    image_id = os.path.splitext(base_name)[0]\n",
    "    return image_id\n",
    "\n",
    "# Apply the function to extract image_id\n",
    "color_var['image_id'] = color_var['file_name'].apply(extract_image_id)\n",
    "color_hist['image_id'] = color_hist['file_name'].apply(extract_image_id)\n",
    "lbp['image_id'] = lbp['file_name'].apply(extract_image_id)\n",
    "glcm['image_id'] = glcm['file_name'].apply(extract_image_id)\n",
    "\n",
    "# Sort feature DataFrames by image_id\n",
    "color_var_sorted = color_var.sort_values(by='image_id').reset_index(drop=True)\n",
    "color_hist_sorted = color_hist.sort_values(by='image_id').reset_index(drop=True)\n",
    "lbp_sorted = lbp.sort_values(by='image_id').reset_index(drop=True)\n",
    "glcm_sorted = glcm.sort_values(by='image_id').reset_index(drop=True)\n",
    "\n",
    "# Sort metadata by image_id\n",
    "metadata_sorted = metadata.sort_values(by='image_id').reset_index(drop=True)"
   ],
   "id": "daab9bb039d79d54",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:52.510394Z",
     "start_time": "2025-04-05T02:49:52.475172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge all features\n",
    "def merge_features(df_list):\n",
    "    # Start with the first DataFrame\n",
    "    merged = df_list[0]\n",
    "    # Merge the rest\n",
    "    for df in df_list[1:]:\n",
    "        merged = pd.merge(merged, df, on='image_id', how='inner', suffixes=('', '_dup'))\n",
    "        # Drop duplicate columns\n",
    "        merged = merged.loc[:, ~merged.columns.str.endswith('_dup')]\n",
    "    return merged\n",
    "\n",
    "# List of sorted feature DataFrames\n",
    "feature_dfs = [color_var_sorted, color_hist_sorted, lbp_sorted, glcm_sorted]\n",
    "merged_features = merge_features(feature_dfs)\n",
    "\n",
    "# Add metadata (dx column)\n",
    "full_data = merged_features.copy()\n",
    "full_data['dx'] = metadata_sorted['dx']"
   ],
   "id": "7f87e245b7b117aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:52.993698Z",
     "start_time": "2025-04-05T02:49:52.976888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Preprocessing\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "full_data['label'] = le.fit_transform(full_data['dx'])\n",
    "\n",
    "# Define X and y (features and target)\n",
    "X = full_data.drop(columns=['label'])\n",
    "y = full_data['label']\n",
    "\n",
    "# Drop non-feature columns\n",
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Output removed columns\n",
    "removed_cols = list(set(X.columns) - set(X_numeric.columns))\n",
    "print(\"removed_cols:\", removed_cols)\n",
    "\n",
    "# Update X\n",
    "X = X_numeric\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=SEED\n",
    ")"
   ],
   "id": "3731eb21fdc303a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed_cols: ['dx', 'folder', 'image_id', 'file_name']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:53.855688Z",
     "start_time": "2025-04-05T02:49:53.851903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "7a4f25b5073a1b22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:49:55.291129Z",
     "start_time": "2025-04-05T02:49:54.451086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load models\n",
    "models = {\n",
    "    'SVM': joblib.load('model_training/best_svm_model.pkl'),\n",
    "    'RandomForest': joblib.load('model_training/best_rf_model.pkl'),\n",
    "    'XGBoost': joblib.load('model_training/xgboost_model.pkl'),\n",
    "    'Bagging': joblib.load('model_training/bagging_dtc_model.pkl'),\n",
    "}\n",
    "\n",
    "# Decompress Ensemble Model\n",
    "ensemble_model_path = 'model_training/best_ensemble_model.pkl.gz'\n",
    "with gzip.open(ensemble_model_path, 'rb') as f:\n",
    "    ensemble_model = joblib.load(f)\n",
    "models['Ensemble'] = ensemble_model # Add to models dictionary"
   ],
   "id": "ef2a25f1d38c017f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:50:00.553508Z",
     "start_time": "2025-04-05T02:49:55.526569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    print(\"=\"*50)"
   ],
   "id": "e51409d42534f117",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM\n",
      "Accuracy: 0.7559\n",
      "F1 Score: 0.7441\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.54      0.49      0.52        65\n",
      "         bcc       0.47      0.47      0.47       103\n",
      "         bkl       0.55      0.48      0.51       220\n",
      "          df       0.75      0.13      0.22        23\n",
      "         mel       0.51      0.40      0.45       223\n",
      "          nv       0.84      0.91      0.88      1341\n",
      "        vasc       0.68      0.46      0.55        28\n",
      "\n",
      "    accuracy                           0.76      2003\n",
      "   macro avg       0.62      0.48      0.51      2003\n",
      "weighted avg       0.74      0.76      0.74      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  32   14    4    0    3   11    1]\n",
      " [  11   48    6    0    4   33    1]\n",
      " [   4   17  106    1   25   66    1]\n",
      " [   4    3    3    3    0   10    0]\n",
      " [   2    0   39    0   89   93    0]\n",
      " [   6   19   35    0   55 1223    3]\n",
      " [   0    2    1    0    0   12   13]]\n",
      "==================================================\n",
      "Model: RandomForest\n",
      "Accuracy: 0.7264\n",
      "F1 Score: 0.7327\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.46      0.51      0.48        65\n",
      "         bcc       0.41      0.57      0.48       103\n",
      "         bkl       0.47      0.50      0.49       220\n",
      "          df       0.50      0.17      0.26        23\n",
      "         mel       0.42      0.48      0.45       223\n",
      "          nv       0.88      0.84      0.86      1341\n",
      "        vasc       1.00      0.46      0.63        28\n",
      "\n",
      "    accuracy                           0.73      2003\n",
      "   macro avg       0.59      0.51      0.52      2003\n",
      "weighted avg       0.75      0.73      0.73      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  33   17    5    0    5    5    0]\n",
      " [  13   59   11    0    6   14    0]\n",
      " [   6   26  110    3   35   40    0]\n",
      " [   4    4    5    4    1    5    0]\n",
      " [   2    3   36    0  107   75    0]\n",
      " [  14   31   65    1  101 1129    0]\n",
      " [   0    5    1    0    1    8   13]]\n",
      "==================================================\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7708\n",
      "F1 Score: 0.7536\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.52      0.40      0.45        65\n",
      "         bcc       0.43      0.34      0.38       103\n",
      "         bkl       0.58      0.48      0.53       220\n",
      "          df       0.67      0.09      0.15        23\n",
      "         mel       0.58      0.44      0.50       223\n",
      "          nv       0.84      0.94      0.89      1341\n",
      "        vasc       0.94      0.57      0.71        28\n",
      "\n",
      "    accuracy                           0.77      2003\n",
      "   macro avg       0.65      0.47      0.52      2003\n",
      "weighted avg       0.75      0.77      0.75      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  26   17    3    0    2   17    0]\n",
      " [  14   35    9    0    1   44    0]\n",
      " [   4   12  106    1   29   68    0]\n",
      " [   3    1    4    2    1   12    0]\n",
      " [   0    2   30    0   98   93    0]\n",
      " [   3   12   28    0   36 1261    1]\n",
      " [   0    2    2    0    1    7   16]]\n",
      "==================================================\n",
      "Model: Bagging\n",
      "Accuracy: 0.7404\n",
      "F1 Score: 0.7098\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.43      0.31      0.36        65\n",
      "         bcc       0.43      0.28      0.34       103\n",
      "         bkl       0.55      0.37      0.44       220\n",
      "          df       1.00      0.04      0.08        23\n",
      "         mel       0.54      0.33      0.41       223\n",
      "          nv       0.80      0.95      0.86      1341\n",
      "        vasc       1.00      0.29      0.44        28\n",
      "\n",
      "    accuracy                           0.74      2003\n",
      "   macro avg       0.68      0.37      0.42      2003\n",
      "weighted avg       0.72      0.74      0.71      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  20   13    7    0    1   24    0]\n",
      " [  11   29    8    0    2   53    0]\n",
      " [   3   12   82    0   26   97    0]\n",
      " [   5    1    3    1    1   12    0]\n",
      " [   2    2   19    0   74  126    0]\n",
      " [   5    8   28    0   31 1269    0]\n",
      " [   0    3    3    0    1   13    8]]\n",
      "==================================================\n",
      "Model: Ensemble\n",
      "Accuracy: 0.7728\n",
      "F1 Score: 0.7638\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.46      0.49      0.47        65\n",
      "         bcc       0.47      0.50      0.49       103\n",
      "         bkl       0.58      0.52      0.55       220\n",
      "          df       0.67      0.17      0.28        23\n",
      "         mel       0.55      0.43      0.48       223\n",
      "          nv       0.86      0.92      0.89      1341\n",
      "        vasc       1.00      0.46      0.63        28\n",
      "\n",
      "    accuracy                           0.77      2003\n",
      "   macro avg       0.66      0.50      0.54      2003\n",
      "weighted avg       0.76      0.77      0.76      2003\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  32   16    4    0    3   10    0]\n",
      " [  17   52    5    0    3   26    0]\n",
      " [   6   18  115    2   26   53    0]\n",
      " [   4    2    3    4    1    9    0]\n",
      " [   1    3   35    0   96   88    0]\n",
      " [  10   16   35    0   44 1236    0]\n",
      " [   0    4    2    0    1    8   13]]\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Neural Networks\n",
    "\n",
    "We also trained neural networks with transfer learning utilizing VGG16 and MobileNetV2 architectures. VGG16 is a deep convolutional neural network architecture that was trained on the ImageNet dataset and was chosen for its complexity. MobileNetV2 is a lightweight model designed for mobile and edge devices, chosen for its efficiency.\n",
    "\n",
    "We trained these models on image data with some data augmentation and tuning, but accuracy was a bit low. The models would likely benefit from additional hyperparameter tuning, more epochs, and more combinations of data augmentation techniques. However, due to computational and time constraints, we did not explore these options further but will provide detail in the final report."
   ],
   "id": "27bbc457a69d63e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:51:49.286901Z",
     "start_time": "2025-04-05T02:51:44.701388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset with images from huggingface\n",
    "train_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"validation\")\n",
    "test_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"test\")"
   ],
   "id": "e4c2f64e215111e4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:51:49.295866Z",
     "start_time": "2025-04-05T02:51:49.293061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save lengths of datasets for later use\n",
    "train_length = len(train_dataset) - 1 # Remove the first row\n",
    "valid_length = len(valid_dataset) - 1\n",
    "test_length = len(test_dataset) - 1"
   ],
   "id": "f31e5e0feca5e846",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:51:49.425958Z",
     "start_time": "2025-04-05T02:51:49.377389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to convert dataset to TensorFlow dataset\n",
    "def convert_to_tf_dataset(dataset):\n",
    "    def generator():\n",
    "        for data in dataset:\n",
    "            yield {'image': data['image'], 'dx': data['dx']}\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature={\n",
    "            'image': tf.TensorSpec(shape=(None, None, 3), dtype=tf.uint8),\n",
    "            'dx': tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Data Augmentation for Images\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "    keras.layers.RandomRotation(0.1),\n",
    "    keras.layers.RandomZoom(0.1),\n",
    "    keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Define normalization layer\n",
    "normalization_layer = keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Extract unique labels from the dataset\n",
    "unique_labels = train_dataset.unique('dx')\n",
    "\n",
    "# Create a lookup table mapping each label to a unique integer\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "\n",
    "# Retrieve number of classes\n",
    "num_classes = len(train_dataset.unique('dx'))\n",
    "\n",
    "# Function to preprocess and augment the dataset\n",
    "def preprocess_data(dataset, augment=False):\n",
    "    def preprocess_image(image, label):\n",
    "        image = tf.image.resize(image, (128, 128))\n",
    "        image = normalization_layer(image)\n",
    "        if augment:\n",
    "            image = data_augmentation(image)\n",
    "        label = label_to_index[label.numpy().decode('utf-8')]  # Convert string labels to integers\n",
    "        label = tf.one_hot(label, num_classes)  # One-hot encode the label\n",
    "        return image, label\n",
    "\n",
    "    def map_fn(data):\n",
    "        image = data['image']\n",
    "        label = data['dx']\n",
    "        image, label = tf.py_function(preprocess_image, [image, label], [tf.float32, tf.float32])\n",
    "        image.set_shape((128, 128, 3))\n",
    "        label.set_shape((num_classes,))\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(map_fn)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset"
   ],
   "id": "6cfeb9ed538a07b2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:51:49.563676Z",
     "start_time": "2025-04-05T02:51:49.515316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert datasets to TensorFlow datasets\n",
    "train_dataset = convert_to_tf_dataset(train_dataset)\n",
    "valid_dataset = convert_to_tf_dataset(valid_dataset)\n",
    "test_dataset = convert_to_tf_dataset(test_dataset)"
   ],
   "id": "f4ffd3ea426f3b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:51:49.686291Z",
     "start_time": "2025-04-05T02:51:49.633768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess the datasets\n",
    "train_dataset = preprocess_data(train_dataset, augment=True) # Repeat the dataset 50 times to match epochs for training\n",
    "valid_dataset = preprocess_data(valid_dataset)\n",
    "test_dataset = preprocess_data(test_dataset)\n",
    "\n",
    "# Remove the first row from each dataset\n",
    "train_dataset = train_dataset.skip(1)\n",
    "valid_dataset = valid_dataset.skip(1)\n",
    "test_dataset = test_dataset.skip(1)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Cache and prefetch the datasets to improve performance\n",
    "train_dataset = train_dataset.take(train_length).cache().repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.cache().take(valid_length).repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().take(test_length).repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = math.ceil(train_length / 32)\n",
    "validation_steps = math.ceil(valid_length / 32)"
   ],
   "id": "76d70b0c1f77e857",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T03:36:31.397259Z",
     "start_time": "2025-04-05T02:52:14.303633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the models\n",
    "vgg16_model = keras.models.load_model('model_training/best_vgg16_model.keras')\n",
    "mobilenet_model = keras.models.load_model('model_training/best_mobilenetv2_model.keras')\n",
    "\n",
    "# Evaluate the models\n",
    "print('VGG16 Model Evaluation:')\n",
    "vgg16_model.evaluate(test_dataset, steps=test_length)\n",
    "\n",
    "print('\\nMobileNetV2 Model Evaluation:')\n",
    "mobilenet_model.evaluate(test_dataset, steps=test_length)"
   ],
   "id": "4895542f1a9ad142",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sj/miniconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Model Evaluation:\n",
      "\u001B[1m1284/1284\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2551s\u001B[0m 2s/step - accuracy: 0.6776 - loss: 1.6830\n",
      "\n",
      "MobileNetV2 Model Evaluation:\n",
      "\u001B[1m1284/1284\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m105s\u001B[0m 81ms/step - accuracy: 0.6789 - loss: 1.4435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.43679678440094, 0.6849641799926758]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
